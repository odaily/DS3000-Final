{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2020</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Project Title</h3> </center>\n",
    "<center><h4>Team Member Names</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.preprocessing import KBinsDiscretizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "Add your summary here (100-150 words)\n",
    "\n",
    "Provide a brief summary of your project. After reading this executive summary, your readers should have a rough understanding of what you did in this project. You can think of this summary in terms of the four sections of the report and write 1-2 sentences describing each section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, orient your readers to your project. You've already written some of these in previous deliverables. Based on your final analysis, revise your problem statement and write a concise introduction section. This section should touch upon the following points, but should be written in full paragraphs. Your writing should incorporate all of these points (and more if you like) in a coherent way. Remember that you are trying to convince your readers that this is an important problem to tackle. \n",
    "\n",
    "Problem Statement\n",
    "* Describe the problem you would like to tackle. \n",
    "* What is the topic of your project? \n",
    "* What do you want to learn about it?\n",
    "\n",
    "Significance of the Problem\n",
    "* Why is it important to tackle this problem in your project?\n",
    "* In what ways could the insights from this project be useful?\n",
    "* **(optional)** Has there been previous work on your topic in terms of applying ML techniques to analyze similar datasets? Do some research into your topic. What algorithms were used? What was the performance of those algorithms? Cite your sources appropriately. You can use the numbered reference format or APA (if you are more comfortable with it).\n",
    "\n",
    "Questions/Hypothesis\n",
    "* End this section with a list of questions and hypotheses\n",
    "* You should tie these questions/hypotheses to the problem statement and its significance\n",
    "    * e.g. Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "    \n",
    "**Requirement:**\n",
    "* You should have at least one question tapping into the comparison of various machine learning algorithms (at least three) in predicting/classifying your target variable from your features variables.\n",
    "* You should have at least one hypothesis regarding the relationship between two variables, which may be different from your ML problem.\n",
    "\n",
    "While this section provides bullet points as prompts, your Introduction should consist of coherent paragraphs. As noted in the rubric, you are required delete all the prompts from this template, except for headings. Failing to do so will result in substantial point deductions.\n",
    "\n",
    "**[IN PROGRESS]**\n",
    "\n",
    "For our final project, we plan to analyze patterns in presidential speech in order to understand how the role of the president in establishing the national social agenda has changed over time. In particular, we’d like to focus on tracking the prevalence of different themes over time using feature analysis. Using our final output dataset, we will be able to visualize the progression and popularity of different social issues in presidential rhetoric at different points in time. For example, we plan to look into such patterns as gender-specific pronouns, and analyze speech readability using the Flesh-Kincaid test. Our finite dataset has 997 rows, restricted by the number of presidential speeches; this data was acquired primarily using an online corpora, and we used web-scraping to acquire the speeches of the 45th president. We have multiple features in the dataset -- for readability, we consider such attributes as word count, sentence count, and average syllables per word, and for sentimentality, we consider the frequencies of gendered pronouns, and terms pertaining to race/religion. The target/outcome variables for our dataset include political party, president, and time period, the last of which is to be indexed using 20-year blocks. We plan to use this data primarily to visualize trends of progressivism in presidential speeches over time; however, we also plan to work towards training a model to predict these target variables.\n",
    "\n",
    "Questions regarding our dataset:\n",
    "\n",
    "* Are there significant presidential speech sentimentality trends over time?\n",
    "* Which visualization types fit best for representing the attributes and trends of our dataset?\n",
    "* What machine learning algorithm (out of the ones we’ve seen used in class) can best classify the presidential speeches?\n",
    "* To what degree of accuracy can we get a machine learning algorithm to predict the aforementioned target variables? (Using cross-validation procedures)\n",
    "* Which feature variable will play the largest role in classification?\n",
    "* Can we train a machine learning classification algorithm to classify the political party from which the speeches came? \n",
    "* (This will utilize only speech data from after 1936, when the Democratic and Republican parties established their modern platforms.)\n",
    "* We also plan to test multiple hypotheses, including:\n",
    "* The frequency of female-gendered terms will increase over time.\n",
    "* The frequency of male-gendered terms will decrease over time. \n",
    "* The use of religious language will decrease over time. \n",
    "* The use of equality-related rhetoric will decrease over time. \n",
    "* Religious language will be a key indicator of political party.\n",
    "\n",
    "\n",
    "Our project primarily tackles a classification problem, as we plan to train our model to predict political party (binary classification), speaker (multiclass classification), and year (multiclass classification using feature discretization, nbins= 20). We also plan to experiment with regressive prediction, utilizing speech year as a continuous outcome variable. Algorithm-wise, we plan to experiment with each of the models covered in lecture, as the sklearn library makes it easy to compare the performance of multiple algorithms on a dataset (kNN, SVM, Naïve-Bayes, Decision Trees; Linear, Polynomial, Ridge, and Lasso regression). We are particularly interested in evaluating the importance of each feature, using univariate and model-based feature selection. As mentioned, we plan to try using feature discretization for the regressive prediction component; we also plan to experiment using both bag-of-words and n-grams for feature extraction. By experimenting with preliminary correlation visualizations, we will be able to gauge whether our features are likely to demonstrate predictive capabilities; either way, we may chose to expand our feature analysis into other linguistic components -- for example, it may be an interesting challenge to determine if there are certain words which maximize prediction accuracy of the model, or consider such features as speech location at different geographical scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "* Describe where you obtained your data. Provide a link to the original source. \n",
    "* If you scraped your data, include your code as a **separate** script file.\n",
    "* Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from local drive.\n",
    "* Describe the dataset (i.e., what it is about) and the number of variables/rows included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sources where we obtained the original data:\n",
    "* Corpus of Speeches, Presidents 1-44: http://www.thegrammarlab.com/?nor-portfolio=corpus-of-presidential-speeches-cops-and-a-clintontrump-corpus\n",
    "* Corpus of Speeches, 45th President: https://millercenter.org/the-presidency/presidential-speeches \n",
    "\n",
    "We have multiple scripts for scraping which we attached. Additionally, when we first created our dataset, we did some of our feature extraction, and most of our preprocessing, this script is called *InitialExtractionAndDFCreation.ipynb* please review it, as the data we clean and extract additional features from is created by the *InitialExtractionAndDFCreation.ipynb* script. Our dataset has 997 rows. Our dataset is finite and has already been approved by a TA, so while it is not the 1000 row minimum, these are all of the presidential speeches which currently exist. \n",
    "\n",
    "Columns in our original Dataset created by *InitialExtractionAndDFCreation.ipynb*:\n",
    "* word_count : the number of words in a given speech (feature)\n",
    "* sentence_count : the number of sentences in a given speech (feature)\n",
    "* average_words : average number of words per sentence (feature)\n",
    "* average_syl_per_word : average number of syllables per word (feature)\n",
    "* flesch_kincaid_score : readability score (feature)\n",
    "* flesch_kincaid_grade_level : score for level of reading difficulty (feature)\n",
    "* total_gendered_terms : a sum of the gendered terms in the speech (feature)\n",
    "* female_gendered_terms : a sum of the female-gendered terms in the speech (feature)\n",
    "* male_gendered_terms : a sum of the male-gendered terms in the speech (feature)\n",
    "* terms_of_equality : a sum of the terms related to the concept of equality in the speech (feature)\n",
    "* terms_for_race : a sum of the terms related race in the speech (feature)\n",
    "* terms_for_religion : a sum of the terms related to religion in the speech (feature)\n",
    "* political_party : indicates the political party of the speech giver (outcome)\n",
    "    * 0 - independent\n",
    "    * 1 - Federalist\n",
    "    * 2 - Democratic-Republican\n",
    "    * 3 - Whig\n",
    "    * 4 - Republican pre-1865\n",
    "    * 5 - Democrat pre-1865\n",
    "    * 6 - National Union\n",
    "    * 7 - Democrat post-1865, pre-1961\n",
    "    * 8 - Republican post-1865, pre-1961\n",
    "    * 9 - Democrat post-1961\n",
    "    * 10 Republican post-1961\n",
    "* president : indicates the president who gave the speech by name (outcome)\n",
    "* time_period : indicates the political party of the speech giver (index indicating 20 year blocks since the beginning of the United States 0 - 11) (outcome)\n",
    "* year (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>average_words</th>\n",
       "      <th>average_syl_per_word</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>total_gendered_terms</th>\n",
       "      <th>female_gendered_terms</th>\n",
       "      <th>male_gendered_terms</th>\n",
       "      <th>terms_of_equality</th>\n",
       "      <th>terms_for_race</th>\n",
       "      <th>terms_for_religion</th>\n",
       "      <th>political_party</th>\n",
       "      <th>president</th>\n",
       "      <th>time_period</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The personal inconveniences to the members of ...</td>\n",
       "      <td>3034</td>\n",
       "      <td>79</td>\n",
       "      <td>39.379747</td>\n",
       "      <td>1.708306</td>\n",
       "      <td>22.341881</td>\n",
       "      <td>19.926110</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>adams</td>\n",
       "      <td>0</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When it was first perceived, in early times, t...</td>\n",
       "      <td>2322</td>\n",
       "      <td>34</td>\n",
       "      <td>68.823529</td>\n",
       "      <td>1.690353</td>\n",
       "      <td>-6.024758</td>\n",
       "      <td>31.197344</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>adams</td>\n",
       "      <td>0</td>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "      <td>2224</td>\n",
       "      <td>59</td>\n",
       "      <td>38.661017</td>\n",
       "      <td>1.681205</td>\n",
       "      <td>25.364122</td>\n",
       "      <td>19.326016</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>adams</td>\n",
       "      <td>0</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As the safety and prosperity of nations ultima...</td>\n",
       "      <td>663</td>\n",
       "      <td>9</td>\n",
       "      <td>73.555556</td>\n",
       "      <td>1.731523</td>\n",
       "      <td>-14.310767</td>\n",
       "      <td>33.528643</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>adams</td>\n",
       "      <td>0</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is with peculiar satisfaction that I meet t...</td>\n",
       "      <td>1500</td>\n",
       "      <td>37</td>\n",
       "      <td>41.459459</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>18.395649</td>\n",
       "      <td>20.993189</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>adams</td>\n",
       "      <td>0</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech  word_count  \\\n",
       "0  The personal inconveniences to the members of ...        3034   \n",
       "1  When it was first perceived, in early times, t...        2322   \n",
       "2  Gentlemen of the Senate and Gentlemen of the H...        2224   \n",
       "3  As the safety and prosperity of nations ultima...         663   \n",
       "4  It is with peculiar satisfaction that I meet t...        1500   \n",
       "\n",
       "   sentence_count  average_words  average_syl_per_word  flesch_kincaid_score  \\\n",
       "0              79      39.379747              1.708306             22.341881   \n",
       "1              34      68.823529              1.690353             -6.024758   \n",
       "2              59      38.661017              1.681205             25.364122   \n",
       "3               9      73.555556              1.731523            -14.310767   \n",
       "4              37      41.459459              1.730000             18.395649   \n",
       "\n",
       "   flesch_kincaid_grade_level  total_gendered_terms  female_gendered_terms  \\\n",
       "0                   19.926110                    28                      0   \n",
       "1                   31.197344                    14                      0   \n",
       "2                   19.326016                    12                      5   \n",
       "3                   33.528643                     5                      0   \n",
       "4                   20.993189                     7                      0   \n",
       "\n",
       "   male_gendered_terms  terms_of_equality  terms_for_race  terms_for_religion  \\\n",
       "0                   28                  3               0                   0   \n",
       "1                   14                  3               1                   3   \n",
       "2                    7                  1               4                   1   \n",
       "3                    5                  0               0                   3   \n",
       "4                    7                  1               0                   0   \n",
       "\n",
       "   political_party president  time_period  year  \n",
       "0                1     adams            0  1797  \n",
       "1                1     adams            0  1797  \n",
       "2                1     adams            0  1798  \n",
       "3                1     adams            0  1798  \n",
       "4                1     adams            0  1799  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/odaily/DS3000-Project/master/final_proj_dataset.csv\"\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Analysis\n",
    "* For your hypotheses, what are your IVs and DVs?\n",
    "* Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables? Why do you think those are important predictors?\n",
    "* Describe why this is a supervised ML problem and identify the sub-category of the learning task (e.g. classification).\n",
    "* What machine learning algorithms are you going to use? **Why?** You should compare at least three algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling\n",
    "In this section, you should do the following and explain why you are doing what you are doing. For each, you should include your code in a cell, followed by a sample output. For instance, if you are one-hot encoding one of your variables, you should first describe what it is and why you are doing it. You should then include your code in a cell, and the sample output should be available as well.\n",
    "\n",
    "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
    "* Perform data wrangling to get your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
    "* Preprocess your variables (e.g., scaling/transforming feature variables to normalize them)\n",
    "* Perform feature extraction (dummy variables, new features from existing features, etc.)\n",
    "* Use one feature selection technique to select a subset of your original features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING \n",
    "# Some of our data has incorrect or missing values for political party, presidents should keep their same political affiliation\n",
    "# as they had the year they first entered office, we will use data about when they entered office, find their political\n",
    "# party for that year, and apply that to all rows for each president.\n",
    "# Also, there are NaN values for time period for the speeches made by Donald Trump, FDR, and Ronald Reagan.\n",
    "# This is because the years for these rows are truncated and are missing a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstYear(presName):\n",
    "    return yearsAndNames[yearsAndNames['name'] == presName]['first year in office'].item()\n",
    "def getPartyIndex(partyRaw, year):\n",
    "    if partyRaw == \"Independent\":\n",
    "        return 0\n",
    "    elif partyRaw == \"Federalist\":\n",
    "        return 1\n",
    "    elif partyRaw == \"Democratic-Republican\" or partyRaw == \"Democratic-Republican/National Republican\":\n",
    "        return 2\n",
    "    elif partyRaw == \"Whig\":\n",
    "        return 3\n",
    "    elif partyRaw == \"Republican\" and year < 1865:\n",
    "        return 4\n",
    "    elif partyRaw == \"Democratic\" and year < 1865:\n",
    "        return 5\n",
    "    elif partyRaw == \"Republican/National Union\" or partyRaw == \"Democratic/National Union\":\n",
    "        return 6\n",
    "    elif partyRaw == \"Democratic\" and year >= 1865 and year < 1961:\n",
    "        return 7\n",
    "    elif partyRaw == \"Republican\" and year >= 1865 and year < 1961:\n",
    "        return 8\n",
    "    elif partyRaw == \"Democratic\" and year >= 1961:\n",
    "        return 9\n",
    "    elif partyRaw == \"Republican\" and year >= 1961:\n",
    "        return 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data to get the year they took office\n",
    "yearsUrl = \"https://gist.githubusercontent.com/namuol/2657233/raw/74135b2637e624848c163759be9cd14ae33f5153/presidents.csv\"\n",
    "yearsDf = pd.read_csv(yearsUrl)\n",
    "yearsAndNames = pd.DataFrame(columns = [\"name\", \"first year in office\"])\n",
    "yearsAndNames[\"first year in office\"] = yearsDf['Took office '].str[-4:]\n",
    "namesRaw = yearsDf[\"President \"].str.split().str[-1].str.lower()\n",
    "yearsAndNames[\"name\"] = namesRaw\n",
    "\n",
    "# changing certain names to match our naming conventions\n",
    "yearsAndNames.iloc[7] = ['vanburen', 1837]\n",
    "yearsAndNames.iloc[22] = ['bharrison', 1889]\n",
    "yearsAndNames.iloc[22] = ['bharrison', 1889]\n",
    "yearsAndNames.iloc[22] = ['bharrison', 1889]\n",
    "yearsAndNames.iloc[31] = ['fdroosevelt', 1933]\n",
    "yearsAndNames.iloc[42] = ['gwbush', 2001]\n",
    "yearsAndNames.iloc[5] = ['jqadams', 1825]\n",
    "yearsAndNames.iloc[35] = ['lbjohnson', 1963]\n",
    "yearsAndNames.loc[44]= ['trump', 2017]\n",
    "\n",
    "\n",
    "parties = []\n",
    "yearsAndNames['party'] = yearsDf['Party ']\n",
    "\n",
    "#adding in trump's party\n",
    "yearsAndNames.loc[44]= ['trump', 2017,'Republican']\n",
    "\n",
    "# parsing party and changing it to be an index \n",
    "for name in yearsAndNames['name']:\n",
    "    first_year = int(getFirstYear(name))\n",
    "    party = yearsAndNames[yearsAndNames['name']==name].party.item().strip()\n",
    "    parties.append(getPartyIndex(party, first_year))\n",
    "# adds the parties to the df\n",
    "yearsAndNames['party'] = parties\n",
    "\n",
    "# sets all president's political party to be the one it was when they entered the office\n",
    "for name in yearsAndNames['name']:\n",
    "    first_year = int(getFirstYear(name))\n",
    "    df.loc[df.president == name, 'political_party'] = yearsAndNames[yearsAndNames['name']==name].party.item()\n",
    "\n",
    "# fixing NaN time period values\n",
    "\n",
    "# getting correct time period for trump from line 898\n",
    "trump_time_period = df.iloc[898]['time_period']\n",
    "# setting all of trump's data to match this\n",
    "df.loc[df.president == 'trump', 'time_period'] = trump_time_period\n",
    "\n",
    "\n",
    "# fixing the truncated years for two presidents\n",
    "df.at[208,'year'] = 1940\n",
    "df.at[814,'year'] = 1987\n",
    "\n",
    "#checking for null values in the df\n",
    "#df.isnull().sum()\n",
    "\n",
    "# Our data is now clean!yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library of gendered terms\n",
    "femaleGendered = [\"she\", \"her\", \"hers\", \"woman\", \"women\", \"girl\", \"girls\", \"female\"]\n",
    "maleGendered = [\"he\", \"him\", \"his\", \"man\", \"men\", \"boy\", \"boys\", \"male\"]\n",
    "equality = [\"equality\", \"equal\", \"fairness\", \"equal rights\", \"equal opportunities\", \"egalitarian\", \"egalitarianism\", \"equity\",\n",
    "           \"equitability\"]\n",
    "race = [\"white\", \"black\", \"asian\", \"indian\", \"african\", \"caucasian\", \"ethnicity\", \"european\", \"hispanic\", \"indigenous\", \n",
    "       \"racism\", \"minority\", \"race\", \"predjudice\", \"racial\", \"latin\", \"latino\", \"latina\", \"jewish\", \"jew\", \"african american\",\n",
    "        \"african-american\",\n",
    "       \"whites\", \"blacks\", \"people of color\", \"native american\", \"native\"]\n",
    "religion = [\"religion\", \"jewish\", \"christian\", \"hindu\", \"judaism\", \"hinduism\", \"christianity\", \"lutherian\", \"catholic\", \n",
    "           \"catholocism\", \"protestant\", \"protestantism\", \"god\", \"buddist\", \"buddism\", \"religous\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that sums the values of the given terms in the given dictionary\n",
    "def sumTermValues(terms, dictionary):\n",
    "    sum = 0\n",
    "    for term in terms:\n",
    "        if dictionary.get(term) is not None:\n",
    "            sum = sum + dictionary.get(term)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImportanceValue(president, terms):\n",
    "    speeches = []\n",
    "    \n",
    "    for speech in df[df['president'] == president]['speech']:\n",
    "        speeches.append(speech.lower())\n",
    "    # cannot use english stop words because it will ignore gendered terms like he/she\n",
    "    vectorizer = TfidfVectorizer(token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "    vect = vectorizer.fit(speeches)\n",
    "    tfidf = vectorizer.fit_transform(speeches)\n",
    "    values = tfidf.toarray().tolist()\n",
    "    flatList = []\n",
    "    for elem in values:\n",
    "        flatList.extend(elem)\n",
    "    keys = vectorizer.get_feature_names()\n",
    "    dictionary = {} \n",
    "    for key in keys: \n",
    "        for value in flatList: \n",
    "            dictionary[key] = value \n",
    "            flatList.remove(value) \n",
    "            break \n",
    "    return sumTermValues(terms, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_president(row, terms):\n",
    "    return getImportanceValue(row['president'], terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female gendered:  0.0\n",
      "male gendered:  0.097964480413952\n",
      "terms for equality:  0.014054214186302049\n",
      "terms for race:  0.0\n",
      "terms for religion:  0.004709638316616817\n"
     ]
    }
   ],
   "source": [
    "# FEATURE EXTRACTION\n",
    "# The feature extraction we will perform includes getting the weight of certain words in the corpus.\n",
    "speeches = []\n",
    "for speech in df['speech']:\n",
    "    speeches.append(speech.lower())\n",
    "# cannot use english stop words because it will ignore gendered terms like he/she\n",
    "vectorizer = TfidfVectorizer(token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', min_df=20)\n",
    "vect = vectorizer.fit(speeches)\n",
    "tfidf = vectorizer.fit_transform(speeches)\n",
    "values = tfidf.toarray().tolist()\n",
    "flatList = []\n",
    "for elem in values:\n",
    "    flatList.extend(elem)\n",
    "keys = vectorizer.get_feature_names()\n",
    "dictionary = {} \n",
    "for key in keys: \n",
    "    for value in flatList: \n",
    "        dictionary[key] = value \n",
    "        flatList.remove(value) \n",
    "        break \n",
    "\n",
    "# doing this for the entire corpus, should I do it per president or per time period -- I think per president \n",
    "# then the presidents of a certain time period will help the classification by time period\n",
    "print(\"female gendered: \", sumTermValues(femaleGendered, dictionary))\n",
    "print(\"male gendered: \", sumTermValues(maleGendered, dictionary))\n",
    "print(\"terms for equality: \", sumTermValues(equality, dictionary))\n",
    "print(\"terms for race: \", sumTermValues(race, dictionary))\n",
    "print(\"terms for religion: \", sumTermValues(religion, dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE EXTRACTION\n",
    "#print(\"trump terms for men: \", getImportanceValue('trump', equality))\n",
    "df['importance_of_equality'] = df.apply (lambda row: label_president(row, equality), axis=1)\n",
    "df['importance_of_race'] = df.apply (lambda row: label_president(row, race), axis=1)\n",
    "df['importance_of_religion'] = df.apply (lambda row: label_president(row, religion), axis=1)\n",
    "df['importance_of_female_gendered_terms'] = df.apply (lambda row: label_president(row, femaleGendered), axis=1)\n",
    "df['importance_of_male_gendered_terms'] = df.apply (lambda row: label_president(row, maleGendered), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>average_words</th>\n",
       "      <th>average_syl_per_word</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>total_gendered_terms</th>\n",
       "      <th>female_gendered_terms</th>\n",
       "      <th>male_gendered_terms</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>importance_of_equality</th>\n",
       "      <th>importance_of_race</th>\n",
       "      <th>importance_of_religion</th>\n",
       "      <th>importance_of_female_gendered_terms</th>\n",
       "      <th>importance_of_male_gendered_terms</th>\n",
       "      <th>timePeriod60YearBin1</th>\n",
       "      <th>timePeriod100YearBin1</th>\n",
       "      <th>timePeriod60YearBin</th>\n",
       "      <th>timePeriod100YearBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>If there is anyone out there who still doubts ...</td>\n",
       "      <td>1980</td>\n",
       "      <td>82</td>\n",
       "      <td>24.743902</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>63.279939</td>\n",
       "      <td>10.580122</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>I stand here today humbled by the task before ...</td>\n",
       "      <td>2415</td>\n",
       "      <td>117</td>\n",
       "      <td>21.324786</td>\n",
       "      <td>1.466253</td>\n",
       "      <td>61.145373</td>\n",
       "      <td>10.028447</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>To Chairman Dean and my great friend Dick Durb...</td>\n",
       "      <td>4706</td>\n",
       "      <td>219</td>\n",
       "      <td>22.082192</td>\n",
       "      <td>1.452189</td>\n",
       "      <td>61.566412</td>\n",
       "      <td>10.157881</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>It is fitting that with the very first bill I ...</td>\n",
       "      <td>913</td>\n",
       "      <td>33</td>\n",
       "      <td>28.242424</td>\n",
       "      <td>1.440307</td>\n",
       "      <td>56.318994</td>\n",
       "      <td>12.420164</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Thank you. Well, I'm excited, too. &lt;Laughter.&gt;...</td>\n",
       "      <td>1534</td>\n",
       "      <td>77</td>\n",
       "      <td>20.584416</td>\n",
       "      <td>1.569100</td>\n",
       "      <td>53.195925</td>\n",
       "      <td>10.953307</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Thank you, everybody. Please have a seat. You ...</td>\n",
       "      <td>2543</td>\n",
       "      <td>143</td>\n",
       "      <td>18.566434</td>\n",
       "      <td>1.549744</td>\n",
       "      <td>56.881694</td>\n",
       "      <td>9.937893</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>6102</td>\n",
       "      <td>291</td>\n",
       "      <td>21.701031</td>\n",
       "      <td>1.518027</td>\n",
       "      <td>56.383380</td>\n",
       "      <td>10.786119</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Thank you so much. Good afternoon. I am honore...</td>\n",
       "      <td>5975</td>\n",
       "      <td>313</td>\n",
       "      <td>19.865815</td>\n",
       "      <td>1.580921</td>\n",
       "      <td>52.925324</td>\n",
       "      <td>10.812530</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Good evening. To the United States Corps of Ca...</td>\n",
       "      <td>4655</td>\n",
       "      <td>240</td>\n",
       "      <td>20.158333</td>\n",
       "      <td>1.602148</td>\n",
       "      <td>50.832552</td>\n",
       "      <td>11.177099</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Madam Speaker, Vice President Biden, Members o...</td>\n",
       "      <td>7264</td>\n",
       "      <td>430</td>\n",
       "      <td>17.669767</td>\n",
       "      <td>1.526019</td>\n",
       "      <td>59.799002</td>\n",
       "      <td>9.308230</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Your Majesties, Your Royal Highnesses, disting...</td>\n",
       "      <td>4293</td>\n",
       "      <td>214</td>\n",
       "      <td>20.785047</td>\n",
       "      <td>1.548567</td>\n",
       "      <td>54.729373</td>\n",
       "      <td>10.789264</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Madam Speaker, Vice President Biden, Members o...</td>\n",
       "      <td>5571</td>\n",
       "      <td>278</td>\n",
       "      <td>20.820144</td>\n",
       "      <td>1.535272</td>\n",
       "      <td>55.818547</td>\n",
       "      <td>10.646065</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Thank you very much. Everybody, please have a ...</td>\n",
       "      <td>3512</td>\n",
       "      <td>213</td>\n",
       "      <td>17.295775</td>\n",
       "      <td>1.522494</td>\n",
       "      <td>60.476771</td>\n",
       "      <td>9.120785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Hello, everybody. I am glad t...</td>\n",
       "      <td>5212</td>\n",
       "      <td>230</td>\n",
       "      <td>23.286957</td>\n",
       "      <td>1.463162</td>\n",
       "      <td>59.415240</td>\n",
       "      <td>10.757224</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Thank you, everybody. Thank you. &lt;Applause.&gt; T...</td>\n",
       "      <td>3579</td>\n",
       "      <td>196</td>\n",
       "      <td>19.030612</td>\n",
       "      <td>1.535624</td>\n",
       "      <td>57.605098</td>\n",
       "      <td>9.952308</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Hello, Ohio! &lt;Applause.&gt; It i...</td>\n",
       "      <td>4249</td>\n",
       "      <td>329</td>\n",
       "      <td>13.653495</td>\n",
       "      <td>1.442928</td>\n",
       "      <td>70.905015</td>\n",
       "      <td>6.761411</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Good evening. Tonight, I'd like to talk to you...</td>\n",
       "      <td>2593</td>\n",
       "      <td>149</td>\n",
       "      <td>18.174497</td>\n",
       "      <td>1.567682</td>\n",
       "      <td>55.761970</td>\n",
       "      <td>9.996704</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Good evening. As we speak, our nation faces a ...</td>\n",
       "      <td>2720</td>\n",
       "      <td>137</td>\n",
       "      <td>20.583942</td>\n",
       "      <td>1.520956</td>\n",
       "      <td>57.269432</td>\n",
       "      <td>10.385017</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Mr. President, Mr. Secretary-...</td>\n",
       "      <td>4112</td>\n",
       "      <td>207</td>\n",
       "      <td>20.570048</td>\n",
       "      <td>1.577335</td>\n",
       "      <td>52.513891</td>\n",
       "      <td>11.044867</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Good afternoon, everybody. La...</td>\n",
       "      <td>8573</td>\n",
       "      <td>344</td>\n",
       "      <td>25.601744</td>\n",
       "      <td>1.429021</td>\n",
       "      <td>59.954024</td>\n",
       "      <td>11.257132</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Thank you. &lt;Applause.&gt; Thank you very much. Pl...</td>\n",
       "      <td>2851</td>\n",
       "      <td>191</td>\n",
       "      <td>15.649215</td>\n",
       "      <td>1.463697</td>\n",
       "      <td>67.122285</td>\n",
       "      <td>7.784818</td>\n",
       "      <td>89</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Good evening. Tonight, I can report to the Ame...</td>\n",
       "      <td>1401</td>\n",
       "      <td>75</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.557459</td>\n",
       "      <td>55.450639</td>\n",
       "      <td>10.328016</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Thank you. Thank you. &lt;Applause.&gt; Thank you ve...</td>\n",
       "      <td>5721</td>\n",
       "      <td>281</td>\n",
       "      <td>21.088968</td>\n",
       "      <td>1.583464</td>\n",
       "      <td>51.468607</td>\n",
       "      <td>11.319578</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "      <td>7071</td>\n",
       "      <td>497</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.503323</td>\n",
       "      <td>64.428838</td>\n",
       "      <td>7.999217</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Good afternoon, everybody. As a candidate for ...</td>\n",
       "      <td>976</td>\n",
       "      <td>51</td>\n",
       "      <td>19.803922</td>\n",
       "      <td>1.561475</td>\n",
       "      <td>54.633200</td>\n",
       "      <td>10.558939</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Thank you very much. Thank you. &lt;Applause.&gt;\\nM...</td>\n",
       "      <td>4299</td>\n",
       "      <td>188</td>\n",
       "      <td>23.563830</td>\n",
       "      <td>1.524308</td>\n",
       "      <td>53.961258</td>\n",
       "      <td>11.586728</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Thank you. &lt;Applause.&gt; Thank ...</td>\n",
       "      <td>4676</td>\n",
       "      <td>341</td>\n",
       "      <td>14.463343</td>\n",
       "      <td>1.475406</td>\n",
       "      <td>67.335331</td>\n",
       "      <td>7.460499</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "      <td>7157</td>\n",
       "      <td>513</td>\n",
       "      <td>14.730994</td>\n",
       "      <td>1.545620</td>\n",
       "      <td>61.123617</td>\n",
       "      <td>8.393400</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>Thank you. &lt;Applause.&gt; Thank you, Governor. To...</td>\n",
       "      <td>1708</td>\n",
       "      <td>104</td>\n",
       "      <td>17.173077</td>\n",
       "      <td>1.399297</td>\n",
       "      <td>71.023765</td>\n",
       "      <td>7.619210</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Tonight, more than 200 years after a former co...</td>\n",
       "      <td>2227</td>\n",
       "      <td>148</td>\n",
       "      <td>15.817568</td>\n",
       "      <td>1.468792</td>\n",
       "      <td>66.520358</td>\n",
       "      <td>7.910598</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Vice President Biden, Mr. Chief Justice,\\nmemb...</td>\n",
       "      <td>2146</td>\n",
       "      <td>113</td>\n",
       "      <td>19.867257</td>\n",
       "      <td>1.537279</td>\n",
       "      <td>56.615960</td>\n",
       "      <td>10.298118</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Thank you! &lt;Applause.&gt; Thank you! Thank you so...</td>\n",
       "      <td>3086</td>\n",
       "      <td>247</td>\n",
       "      <td>13.267206</td>\n",
       "      <td>1.506805</td>\n",
       "      <td>65.893089</td>\n",
       "      <td>7.364509</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "      <td>6929</td>\n",
       "      <td>443</td>\n",
       "      <td>16.519187</td>\n",
       "      <td>1.550152</td>\n",
       "      <td>58.925205</td>\n",
       "      <td>9.144271</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Good morning, everybody. As you know, I just m...</td>\n",
       "      <td>5320</td>\n",
       "      <td>277</td>\n",
       "      <td>19.895307</td>\n",
       "      <td>1.446617</td>\n",
       "      <td>64.257504</td>\n",
       "      <td>9.239245</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>Thank you. &lt;Applause.&gt; Thank you so much. Well...</td>\n",
       "      <td>5535</td>\n",
       "      <td>381</td>\n",
       "      <td>15.320210</td>\n",
       "      <td>1.539476</td>\n",
       "      <td>61.045312</td>\n",
       "      <td>8.550699</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Hello, Connecticut. &lt;Applause.&gt; Thank you. Wel...</td>\n",
       "      <td>3287</td>\n",
       "      <td>239</td>\n",
       "      <td>14.506276</td>\n",
       "      <td>1.450867</td>\n",
       "      <td>69.367777</td>\n",
       "      <td>7.187679</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>I wanted to come out here, first of all, to te...</td>\n",
       "      <td>2163</td>\n",
       "      <td>80</td>\n",
       "      <td>27.687500</td>\n",
       "      <td>1.465095</td>\n",
       "      <td>54.785169</td>\n",
       "      <td>12.496243</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Hello, Warrensburg! &lt;Applause.&gt; Hello, Mules! ...</td>\n",
       "      <td>4424</td>\n",
       "      <td>277</td>\n",
       "      <td>16.801444</td>\n",
       "      <td>1.449819</td>\n",
       "      <td>67.126833</td>\n",
       "      <td>8.070429</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>My fellow Americans, tonight I want to talk to...</td>\n",
       "      <td>2217</td>\n",
       "      <td>115</td>\n",
       "      <td>19.965217</td>\n",
       "      <td>1.585927</td>\n",
       "      <td>52.400886</td>\n",
       "      <td>10.910373</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Thank you. &lt;Applause.&gt; Thank you, everybody. T...</td>\n",
       "      <td>6585</td>\n",
       "      <td>334</td>\n",
       "      <td>20.592814</td>\n",
       "      <td>1.546090</td>\n",
       "      <td>55.134113</td>\n",
       "      <td>10.685055</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>6845</td>\n",
       "      <td>351</td>\n",
       "      <td>20.245014</td>\n",
       "      <td>1.549452</td>\n",
       "      <td>55.202658</td>\n",
       "      <td>10.589091</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>My fellow Americans, tonight, I'd like to talk...</td>\n",
       "      <td>2248</td>\n",
       "      <td>123</td>\n",
       "      <td>18.975610</td>\n",
       "      <td>1.504448</td>\n",
       "      <td>60.298422</td>\n",
       "      <td>9.562979</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>6847</td>\n",
       "      <td>464</td>\n",
       "      <td>15.543103</td>\n",
       "      <td>1.537316</td>\n",
       "      <td>61.001849</td>\n",
       "      <td>8.612135</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>&lt;THE PRESIDENT:&gt; Giving all praise and honor t...</td>\n",
       "      <td>2860</td>\n",
       "      <td>207</td>\n",
       "      <td>14.714976</td>\n",
       "      <td>1.507343</td>\n",
       "      <td>64.378111</td>\n",
       "      <td>7.935484</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>&lt;AUDIENCE MEMBER: We love you, President Obama...</td>\n",
       "      <td>3752</td>\n",
       "      <td>241</td>\n",
       "      <td>16.319502</td>\n",
       "      <td>1.506397</td>\n",
       "      <td>62.829554</td>\n",
       "      <td>8.550086</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Thank you. &lt;Applause.&gt; Muchas gracias. Thank y...</td>\n",
       "      <td>4125</td>\n",
       "      <td>275</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>1.559758</td>\n",
       "      <td>58.842509</td>\n",
       "      <td>8.977139</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>6118</td>\n",
       "      <td>436</td>\n",
       "      <td>14.830275</td>\n",
       "      <td>1.531710</td>\n",
       "      <td>62.199629</td>\n",
       "      <td>8.267982</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>Hello Rutgers! &lt;Applause.&gt; R-U rah-rah! &lt;Appla...</td>\n",
       "      <td>4933</td>\n",
       "      <td>434</td>\n",
       "      <td>12.329493</td>\n",
       "      <td>1.534158</td>\n",
       "      <td>64.530822</td>\n",
       "      <td>7.321563</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.148106</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                speech  word_count  \\\n",
       "678  If there is anyone out there who still doubts ...        1980   \n",
       "679  I stand here today humbled by the task before ...        2415   \n",
       "680  To Chairman Dean and my great friend Dick Durb...        4706   \n",
       "681  It is fitting that with the very first bill I ...         913   \n",
       "682  Thank you. Well, I'm excited, too. <Laughter.>...        1534   \n",
       "683  Thank you, everybody. Please have a seat. You ...        2543   \n",
       "684  Madam Speaker, Mr. Vice President, Members of ...        6102   \n",
       "685  Thank you so much. Good afternoon. I am honore...        5975   \n",
       "686  Good evening. To the United States Corps of Ca...        4655   \n",
       "687  Madam Speaker, Vice President Biden, Members o...        7264   \n",
       "688  Your Majesties, Your Royal Highnesses, disting...        4293   \n",
       "689  Madam Speaker, Vice President Biden, Members o...        5571   \n",
       "690  Thank you very much. Everybody, please have a ...        3512   \n",
       "691  <THE PRESIDENT:> Hello, everybody. I am glad t...        5212   \n",
       "692  Thank you, everybody. Thank you. <Applause.> T...        3579   \n",
       "693  <THE PRESIDENT:> Hello, Ohio! <Applause.> It i...        4249   \n",
       "694  Good evening. Tonight, I'd like to talk to you...        2593   \n",
       "695  Good evening. As we speak, our nation faces a ...        2720   \n",
       "696  <THE PRESIDENT:> Mr. President, Mr. Secretary-...        4112   \n",
       "697  <THE PRESIDENT:> Good afternoon, everybody. La...        8573   \n",
       "698  Thank you. <Applause.> Thank you very much. Pl...        2851   \n",
       "699  Good evening. Tonight, I can report to the Ame...        1401   \n",
       "700  Thank you. Thank you. <Applause.> Thank you ve...        5721   \n",
       "701  Mr. Speaker, Mr. Vice President, members of Co...        7071   \n",
       "702  Good afternoon, everybody. As a candidate for ...         976   \n",
       "703  Thank you very much. Thank you. <Applause.>\\nM...        4299   \n",
       "704  <THE PRESIDENT:> Thank you. <Applause.> Thank ...        4676   \n",
       "705  Mr. Speaker, Mr. Vice President, members of Co...        7157   \n",
       "706  Thank you. <Applause.> Thank you, Governor. To...        1708   \n",
       "707  Tonight, more than 200 years after a former co...        2227   \n",
       "708  Vice President Biden, Mr. Chief Justice,\\nmemb...        2146   \n",
       "709  Thank you! <Applause.> Thank you! Thank you so...        3086   \n",
       "710  Mr. Speaker, Mr. Vice President, members of Co...        6929   \n",
       "711  Good morning, everybody. As you know, I just m...        5320   \n",
       "712  Thank you. <Applause.> Thank you so much. Well...        5535   \n",
       "713  Hello, Connecticut. <Applause.> Thank you. Wel...        3287   \n",
       "714  I wanted to come out here, first of all, to te...        2163   \n",
       "715  Hello, Warrensburg! <Applause.> Hello, Mules! ...        4424   \n",
       "716  My fellow Americans, tonight I want to talk to...        2217   \n",
       "717  Thank you. <Applause.> Thank you, everybody. T...        6585   \n",
       "718  Mr. Speaker, Mr. Vice President, Members of Co...        6845   \n",
       "719  My fellow Americans, tonight, I'd like to talk...        2248   \n",
       "720  Mr. Speaker, Mr. Vice President, Members of Co...        6847   \n",
       "721  <THE PRESIDENT:> Giving all praise and honor t...        2860   \n",
       "722  <AUDIENCE MEMBER: We love you, President Obama...        3752   \n",
       "723  Thank you. <Applause.> Muchas gracias. Thank y...        4125   \n",
       "724  Mr. Speaker, Mr. Vice President, Members of Co...        6118   \n",
       "725  Hello Rutgers! <Applause.> R-U rah-rah! <Appla...        4933   \n",
       "\n",
       "     sentence_count  average_words  average_syl_per_word  \\\n",
       "678              82      24.743902              1.400000   \n",
       "679             117      21.324786              1.466253   \n",
       "680             219      22.082192              1.452189   \n",
       "681              33      28.242424              1.440307   \n",
       "682              77      20.584416              1.569100   \n",
       "683             143      18.566434              1.549744   \n",
       "684             291      21.701031              1.518027   \n",
       "685             313      19.865815              1.580921   \n",
       "686             240      20.158333              1.602148   \n",
       "687             430      17.669767              1.526019   \n",
       "688             214      20.785047              1.548567   \n",
       "689             278      20.820144              1.535272   \n",
       "690             213      17.295775              1.522494   \n",
       "691             230      23.286957              1.463162   \n",
       "692             196      19.030612              1.535624   \n",
       "693             329      13.653495              1.442928   \n",
       "694             149      18.174497              1.567682   \n",
       "695             137      20.583942              1.520956   \n",
       "696             207      20.570048              1.577335   \n",
       "697             344      25.601744              1.429021   \n",
       "698             191      15.649215              1.463697   \n",
       "699              75      19.333333              1.557459   \n",
       "700             281      21.088968              1.583464   \n",
       "701             497      15.000000              1.503323   \n",
       "702              51      19.803922              1.561475   \n",
       "703             188      23.563830              1.524308   \n",
       "704             341      14.463343              1.475406   \n",
       "705             513      14.730994              1.545620   \n",
       "706             104      17.173077              1.399297   \n",
       "707             148      15.817568              1.468792   \n",
       "708             113      19.867257              1.537279   \n",
       "709             247      13.267206              1.506805   \n",
       "710             443      16.519187              1.550152   \n",
       "711             277      19.895307              1.446617   \n",
       "712             381      15.320210              1.539476   \n",
       "713             239      14.506276              1.450867   \n",
       "714              80      27.687500              1.465095   \n",
       "715             277      16.801444              1.449819   \n",
       "716             115      19.965217              1.585927   \n",
       "717             334      20.592814              1.546090   \n",
       "718             351      20.245014              1.549452   \n",
       "719             123      18.975610              1.504448   \n",
       "720             464      15.543103              1.537316   \n",
       "721             207      14.714976              1.507343   \n",
       "722             241      16.319502              1.506397   \n",
       "723             275      15.800000              1.559758   \n",
       "724             436      14.830275              1.531710   \n",
       "725             434      12.329493              1.534158   \n",
       "\n",
       "     flesch_kincaid_score  flesch_kincaid_grade_level  total_gendered_terms  \\\n",
       "678             63.279939                   10.580122                    29   \n",
       "679             61.145373                   10.028447                    11   \n",
       "680             61.566412                   10.157881                    61   \n",
       "681             56.318994                   12.420164                    33   \n",
       "682             53.195925                   10.953307                    49   \n",
       "683             56.881694                    9.937893                     7   \n",
       "684             56.383380                   10.786119                    21   \n",
       "685             52.925324                   10.812530                    22   \n",
       "686             50.832552                   11.177099                    12   \n",
       "687             59.799002                    9.308230                    28   \n",
       "688             54.729373                   10.789264                    18   \n",
       "689             55.818547                   10.646065                    42   \n",
       "690             60.476771                    9.120785                     1   \n",
       "691             59.415240                   10.757224                    11   \n",
       "692             57.605098                    9.952308                    11   \n",
       "693             70.905015                    6.761411                    84   \n",
       "694             55.761970                    9.996704                    10   \n",
       "695             57.269432                   10.385017                    14   \n",
       "696             52.513891                   11.044867                    13   \n",
       "697             59.954024                   11.257132                    15   \n",
       "698             67.122285                    7.784818                    89   \n",
       "699             55.450639                   10.328016                     8   \n",
       "700             51.468607                   11.319578                    40   \n",
       "701             64.428838                    7.999217                    37   \n",
       "702             54.633200                   10.558939                     2   \n",
       "703             53.961258                   11.586728                    14   \n",
       "704             67.335331                    7.460499                    42   \n",
       "705             61.123617                    8.393400                    26   \n",
       "706             71.023765                    7.619210                     4   \n",
       "707             66.520358                    7.910598                    11   \n",
       "708             56.615960                   10.298118                    12   \n",
       "709             65.893089                    7.364509                    32   \n",
       "710             58.925205                    9.144271                    44   \n",
       "711             64.257504                    9.239245                    10   \n",
       "712             61.045312                    8.550699                    15   \n",
       "713             69.367777                    7.187679                    31   \n",
       "714             54.785169                   12.496243                    18   \n",
       "715             67.126833                    8.070429                     3   \n",
       "716             52.400886                   10.910373                     8   \n",
       "717             55.134113                   10.685055                    26   \n",
       "718             55.202658                   10.589091                    70   \n",
       "719             60.298422                    9.562979                    20   \n",
       "720             61.001849                    8.612135                    28   \n",
       "721             64.378111                    7.935484                    71   \n",
       "722             62.829554                    8.550086                    34   \n",
       "723             58.842509                    8.977139                    38   \n",
       "724             62.199629                    8.267982                    30   \n",
       "725             64.530822                    7.321563                    15   \n",
       "\n",
       "     female_gendered_terms  male_gendered_terms  ...  year  \\\n",
       "678                     18                   11  ...  2008   \n",
       "679                      4                    7  ...  2009   \n",
       "680                     23                   38  ...  2008   \n",
       "681                     31                    2  ...  2009   \n",
       "682                     46                    3  ...  2009   \n",
       "683                      2                    5  ...  2009   \n",
       "684                     11                   10  ...  2009   \n",
       "685                     14                    8  ...  2009   \n",
       "686                      5                    7  ...  2009   \n",
       "687                     16                   12  ...  2010   \n",
       "688                      8                   10  ...  2009   \n",
       "689                      8                   34  ...  2009   \n",
       "690                      0                    1  ...  2010   \n",
       "691                      3                    8  ...  2010   \n",
       "692                      6                    5  ...  2010   \n",
       "693                     83                    1  ...  2010   \n",
       "694                      4                    6  ...  2010   \n",
       "695                      4                   10  ...  2010   \n",
       "696                      8                    5  ...  2010   \n",
       "697                      4                   11  ...  2010   \n",
       "698                     52                   37  ...  2011   \n",
       "699                      0                    8  ...  2011   \n",
       "700                     13                   27  ...  2011   \n",
       "701                     13                   24  ...  2011   \n",
       "702                      1                    1  ...  2011   \n",
       "703                      7                    7  ...  2011   \n",
       "704                     12                   30  ...  2012   \n",
       "705                      8                   18  ...  2012   \n",
       "706                      0                    4  ...  2012   \n",
       "707                      5                    6  ...  2012   \n",
       "708                      7                    5  ...  2013   \n",
       "709                      5                   27  ...  2013   \n",
       "710                     32                   12  ...  2013   \n",
       "711                      4                    6  ...  2013   \n",
       "712                      1                   14  ...  2013   \n",
       "713                     16                   15  ...  2013   \n",
       "714                      4                   14  ...  2013   \n",
       "715                      3                    0  ...  2013   \n",
       "716                      0                    8  ...  2013   \n",
       "717                     12                   14  ...  2013   \n",
       "718                     33                   37  ...  2014   \n",
       "719                     20                    0  ...  2014   \n",
       "720                     13                   15  ...  2015   \n",
       "721                      0                   71  ...  2015   \n",
       "722                     12                   22  ...  2015   \n",
       "723                     15                   23  ...  2016   \n",
       "724                      7                   23  ...  2016   \n",
       "725                      8                    7  ...  2016   \n",
       "\n",
       "     importance_of_equality  importance_of_race  importance_of_religion  \\\n",
       "678                     0.0              0.0721                0.011091   \n",
       "679                     0.0              0.0721                0.011091   \n",
       "680                     0.0              0.0721                0.011091   \n",
       "681                     0.0              0.0721                0.011091   \n",
       "682                     0.0              0.0721                0.011091   \n",
       "683                     0.0              0.0721                0.011091   \n",
       "684                     0.0              0.0721                0.011091   \n",
       "685                     0.0              0.0721                0.011091   \n",
       "686                     0.0              0.0721                0.011091   \n",
       "687                     0.0              0.0721                0.011091   \n",
       "688                     0.0              0.0721                0.011091   \n",
       "689                     0.0              0.0721                0.011091   \n",
       "690                     0.0              0.0721                0.011091   \n",
       "691                     0.0              0.0721                0.011091   \n",
       "692                     0.0              0.0721                0.011091   \n",
       "693                     0.0              0.0721                0.011091   \n",
       "694                     0.0              0.0721                0.011091   \n",
       "695                     0.0              0.0721                0.011091   \n",
       "696                     0.0              0.0721                0.011091   \n",
       "697                     0.0              0.0721                0.011091   \n",
       "698                     0.0              0.0721                0.011091   \n",
       "699                     0.0              0.0721                0.011091   \n",
       "700                     0.0              0.0721                0.011091   \n",
       "701                     0.0              0.0721                0.011091   \n",
       "702                     0.0              0.0721                0.011091   \n",
       "703                     0.0              0.0721                0.011091   \n",
       "704                     0.0              0.0721                0.011091   \n",
       "705                     0.0              0.0721                0.011091   \n",
       "706                     0.0              0.0721                0.011091   \n",
       "707                     0.0              0.0721                0.011091   \n",
       "708                     0.0              0.0721                0.011091   \n",
       "709                     0.0              0.0721                0.011091   \n",
       "710                     0.0              0.0721                0.011091   \n",
       "711                     0.0              0.0721                0.011091   \n",
       "712                     0.0              0.0721                0.011091   \n",
       "713                     0.0              0.0721                0.011091   \n",
       "714                     0.0              0.0721                0.011091   \n",
       "715                     0.0              0.0721                0.011091   \n",
       "716                     0.0              0.0721                0.011091   \n",
       "717                     0.0              0.0721                0.011091   \n",
       "718                     0.0              0.0721                0.011091   \n",
       "719                     0.0              0.0721                0.011091   \n",
       "720                     0.0              0.0721                0.011091   \n",
       "721                     0.0              0.0721                0.011091   \n",
       "722                     0.0              0.0721                0.011091   \n",
       "723                     0.0              0.0721                0.011091   \n",
       "724                     0.0              0.0721                0.011091   \n",
       "725                     0.0              0.0721                0.011091   \n",
       "\n",
       "    importance_of_female_gendered_terms  importance_of_male_gendered_terms  \\\n",
       "678                            0.148106                           0.072359   \n",
       "679                            0.148106                           0.072359   \n",
       "680                            0.148106                           0.072359   \n",
       "681                            0.148106                           0.072359   \n",
       "682                            0.148106                           0.072359   \n",
       "683                            0.148106                           0.072359   \n",
       "684                            0.148106                           0.072359   \n",
       "685                            0.148106                           0.072359   \n",
       "686                            0.148106                           0.072359   \n",
       "687                            0.148106                           0.072359   \n",
       "688                            0.148106                           0.072359   \n",
       "689                            0.148106                           0.072359   \n",
       "690                            0.148106                           0.072359   \n",
       "691                            0.148106                           0.072359   \n",
       "692                            0.148106                           0.072359   \n",
       "693                            0.148106                           0.072359   \n",
       "694                            0.148106                           0.072359   \n",
       "695                            0.148106                           0.072359   \n",
       "696                            0.148106                           0.072359   \n",
       "697                            0.148106                           0.072359   \n",
       "698                            0.148106                           0.072359   \n",
       "699                            0.148106                           0.072359   \n",
       "700                            0.148106                           0.072359   \n",
       "701                            0.148106                           0.072359   \n",
       "702                            0.148106                           0.072359   \n",
       "703                            0.148106                           0.072359   \n",
       "704                            0.148106                           0.072359   \n",
       "705                            0.148106                           0.072359   \n",
       "706                            0.148106                           0.072359   \n",
       "707                            0.148106                           0.072359   \n",
       "708                            0.148106                           0.072359   \n",
       "709                            0.148106                           0.072359   \n",
       "710                            0.148106                           0.072359   \n",
       "711                            0.148106                           0.072359   \n",
       "712                            0.148106                           0.072359   \n",
       "713                            0.148106                           0.072359   \n",
       "714                            0.148106                           0.072359   \n",
       "715                            0.148106                           0.072359   \n",
       "716                            0.148106                           0.072359   \n",
       "717                            0.148106                           0.072359   \n",
       "718                            0.148106                           0.072359   \n",
       "719                            0.148106                           0.072359   \n",
       "720                            0.148106                           0.072359   \n",
       "721                            0.148106                           0.072359   \n",
       "722                            0.148106                           0.072359   \n",
       "723                            0.148106                           0.072359   \n",
       "724                            0.148106                           0.072359   \n",
       "725                            0.148106                           0.072359   \n",
       "\n",
       "     timePeriod60YearBin1  timePeriod100YearBin1  timePeriod60YearBin  \\\n",
       "678                   3.0                    1.0                  3.0   \n",
       "679                   3.0                    1.0                  3.0   \n",
       "680                   3.0                    1.0                  3.0   \n",
       "681                   3.0                    1.0                  3.0   \n",
       "682                   3.0                    1.0                  3.0   \n",
       "683                   3.0                    1.0                  3.0   \n",
       "684                   3.0                    1.0                  3.0   \n",
       "685                   3.0                    1.0                  3.0   \n",
       "686                   3.0                    1.0                  3.0   \n",
       "687                   3.0                    1.0                  3.0   \n",
       "688                   3.0                    1.0                  3.0   \n",
       "689                   3.0                    1.0                  3.0   \n",
       "690                   3.0                    1.0                  3.0   \n",
       "691                   3.0                    1.0                  3.0   \n",
       "692                   3.0                    1.0                  3.0   \n",
       "693                   3.0                    1.0                  3.0   \n",
       "694                   3.0                    1.0                  3.0   \n",
       "695                   3.0                    1.0                  3.0   \n",
       "696                   3.0                    1.0                  3.0   \n",
       "697                   3.0                    1.0                  3.0   \n",
       "698                   3.0                    1.0                  3.0   \n",
       "699                   3.0                    1.0                  3.0   \n",
       "700                   3.0                    1.0                  3.0   \n",
       "701                   3.0                    1.0                  3.0   \n",
       "702                   3.0                    1.0                  3.0   \n",
       "703                   3.0                    1.0                  3.0   \n",
       "704                   3.0                    1.0                  3.0   \n",
       "705                   3.0                    1.0                  3.0   \n",
       "706                   3.0                    1.0                  3.0   \n",
       "707                   3.0                    1.0                  3.0   \n",
       "708                   3.0                    1.0                  3.0   \n",
       "709                   3.0                    1.0                  3.0   \n",
       "710                   3.0                    1.0                  3.0   \n",
       "711                   3.0                    1.0                  3.0   \n",
       "712                   3.0                    1.0                  3.0   \n",
       "713                   3.0                    1.0                  3.0   \n",
       "714                   3.0                    1.0                  3.0   \n",
       "715                   3.0                    1.0                  3.0   \n",
       "716                   3.0                    1.0                  3.0   \n",
       "717                   3.0                    1.0                  3.0   \n",
       "718                   3.0                    1.0                  3.0   \n",
       "719                   3.0                    1.0                  3.0   \n",
       "720                   3.0                    1.0                  3.0   \n",
       "721                   3.0                    1.0                  3.0   \n",
       "722                   3.0                    1.0                  3.0   \n",
       "723                   3.0                    1.0                  3.0   \n",
       "724                   3.0                    1.0                  3.0   \n",
       "725                   3.0                    1.0                  3.0   \n",
       "\n",
       "     timePeriod100YearBin  \n",
       "678                   1.0  \n",
       "679                   1.0  \n",
       "680                   1.0  \n",
       "681                   1.0  \n",
       "682                   1.0  \n",
       "683                   1.0  \n",
       "684                   1.0  \n",
       "685                   1.0  \n",
       "686                   1.0  \n",
       "687                   1.0  \n",
       "688                   1.0  \n",
       "689                   1.0  \n",
       "690                   1.0  \n",
       "691                   1.0  \n",
       "692                   1.0  \n",
       "693                   1.0  \n",
       "694                   1.0  \n",
       "695                   1.0  \n",
       "696                   1.0  \n",
       "697                   1.0  \n",
       "698                   1.0  \n",
       "699                   1.0  \n",
       "700                   1.0  \n",
       "701                   1.0  \n",
       "702                   1.0  \n",
       "703                   1.0  \n",
       "704                   1.0  \n",
       "705                   1.0  \n",
       "706                   1.0  \n",
       "707                   1.0  \n",
       "708                   1.0  \n",
       "709                   1.0  \n",
       "710                   1.0  \n",
       "711                   1.0  \n",
       "712                   1.0  \n",
       "713                   1.0  \n",
       "714                   1.0  \n",
       "715                   1.0  \n",
       "716                   1.0  \n",
       "717                   1.0  \n",
       "718                   1.0  \n",
       "719                   1.0  \n",
       "720                   1.0  \n",
       "721                   1.0  \n",
       "722                   1.0  \n",
       "723                   1.0  \n",
       "724                   1.0  \n",
       "725                   1.0  \n",
       "\n",
       "[48 rows x 26 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FEATURE EXTRACTION -- MORE LIKE OUTCOME EXTRACTION\n",
    "# creating bins of 61 year periods of time and appending this to the dataframe\n",
    "discretizer = KBinsDiscretizer(n_bins = 4, encode = 'ordinal', strategy = 'quantile')\n",
    "time_period_discretized = discretizer.fit_transform(df['time_period'].values.reshape(-1, 1))\n",
    "time_period_df = pd.DataFrame(time_period_discretized, columns = ['timePeriod60YearBin'])\n",
    "df = pd.concat([df, time_period_df], axis=1, sort=False)\n",
    "#creating bins of 122 year periods of time and appending this to the dataframe\n",
    "discretizer = KBinsDiscretizer(n_bins = 2, encode = 'ordinal', strategy = 'quantile')\n",
    "time_period_discretized2 = discretizer.fit_transform(df['time_period'].values.reshape(-1, 1))\n",
    "time_period_df2 = pd.DataFrame(time_period_discretized2, columns = ['timePeriod100YearBin'])\n",
    "df = pd.concat([df, time_period_df2], axis=1, sort=False)\n",
    "df[df['president'] == 'obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original results: \n",
      "r2_score for training set:  0.8932183414736633\n",
      "r2_score for testing set:  0.9101737557399923\n",
      "\n",
      "With selected features from model based selection: \n",
      "r2_score for training set:  0.8932183414736633\n",
      "r2_score for testing set:  0.9101737557399923\n",
      "\n",
      "original results: \n",
      "r2_score for training set:  0.8932183414736633\n",
      "r2_score for testing set:  0.9101737557399923\n",
      "\n",
      "With Selected Feature from RFE: \n",
      "r2_score for training set:  0.8809131133074091\n",
      "r2_score for testing set:  0.8983732597246381\n",
      "\n",
      "original results: \n",
      "r2_score for training set:  0.8932183414736633\n",
      "r2_score for testing set:  0.9101737557399923\n",
      "\n",
      "With Selected Features from Univariate: \n",
      "r2_score for training set:  0.8681246203657097\n",
      "r2_score for testing set:  0.8832530491617652\n"
     ]
    }
   ],
   "source": [
    "#FEATURE SELECTION\n",
    "y = df ['political_party']\n",
    "X = df.drop(columns=['timePeriod60YearBin', 'timePeriod100YearBin', 'political_party', 'time_period', 'president', 'speech'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=300)\n",
    "#X_validation, X_train, y_validation, y_train = train_test_split(\n",
    "#    X_validation_and_train, y_validation_and_train, test_size=0.50, random_state=300)\n",
    "selector = SelectFromModel(estimator=DecisionTreeRegressor(random_state = 3000), threshold = 'median').fit(X, y)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X=X_train, y=y_train)\n",
    "print('original results: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test)))\n",
    "\n",
    "model = LinearRegression().fit(X=X_train_selected, y=y_train)\n",
    "print()\n",
    "print('With selected features from model based selection: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train_selected)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test)))\n",
    "\n",
    "# not the results we want\n",
    "\n",
    "select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 10)\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "print()\n",
    "model = LinearRegression().fit(X=X_train, y=y_train)\n",
    "print('original results: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test)))\n",
    "print()\n",
    "model = LinearRegression().fit(X=X_train_selected, y=y_train)\n",
    "print('With Selected Feature from RFE: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train_selected)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test_selected)))\n",
    "\n",
    "# Since selecting features causes decrease in accuracy of our model\n",
    "# we will decline to feature select\n",
    "\n",
    "select = SelectKBest(score_func = f_regression, k = 10)\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "print()\n",
    "model = LinearRegression().fit(X=X_train, y=y_train)\n",
    "print('original results: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test)))\n",
    "print()\n",
    "model = LinearRegression().fit(X=X_train_selected, y=y_train)\n",
    "print('With Selected Features from Univariate: ')\n",
    "print('r2_score for training set: ', r2_score(y_train, model.predict(X_train_selected)))\n",
    "print('r2_score for testing set: ', r2_score(y_test, model.predict(X_test_selected)))\n",
    "\n",
    "#Since feature selection only decreases our model's accuracy we will decline to feature select\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'final_proj_dataset_with_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration\n",
    "* Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "* You should have at least three visualizations (and at least two different visualization types)\n",
    "* For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "* If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and embed those into the cells in Jupyter Notebook). This is a requirement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Construction\n",
    "* Conduct your hypothesis test(s) here.\n",
    "* For your machine learning question(s), use the Training, Validation, and Testing approach through GridSearch\n",
    "* Apply machine learning algorithms (apply at least three different algorithms)\n",
    "* Train your algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your **validation set**\n",
    "    * Use at least two different metrics \n",
    "* Evaluate your results from multiple ML models and hypothesis tests\n",
    "    * What was the performance of each algorithm in plain English? Is there any indication of overfitting/underfitting?\n",
    "    * Was there a significant difference? Use the template from lecture slides when reporting the results of your hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your **testing set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "* Interpret your findings from 3.4., 3.5, and 3.6\n",
    "    * Which algorithms did you compare?\n",
    "    * Which algorithm(s) revealed best performance?\n",
    "    * Which algorithm(s) should be used for your predictive model?\n",
    "    * Based on your findings, can we use the features in your dataset to predict the outcome variable you identified using the algorithms you've applied? (It is okay if the answer is no. We're interested in the process, not the performance of the model.)\n",
    "* For your hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "\n",
    "* End this section with a conclusion paragraph containing some pointers for future work\n",
    "    * (e.g., get more data/features, perform another analysis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "* Describe each team member's contributions to the report (who did what in each section)\n",
    "* Remember this is a team effort!\n",
    "* Each member of your team will provide peer evaluation of other team members. Your final grade on the project will be based on those peer evaluations. A survey will be shared after the deadline for this deliverable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
