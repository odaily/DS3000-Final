{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../final_proj_dataset.csv\")\n",
    "text = df['speech']\n",
    "target_party = df['political_party']\n",
    "target_pres = df['president']\n",
    "target_period = df['time_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "992    28\n",
       "993    28\n",
       "994    28\n",
       "995    28\n",
       "996    28\n",
       "Name: president, Length: 997, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "keyVals = json.load(open('../presidentKeys.json'))\n",
    "target_pres = target_pres.apply(lambda x: list(keyVals.keys())[list(keyVals.values()).index(x)])\n",
    "target_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "estimators = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(alpha = 0.5),\n",
    "    \"k-Nearest Neighbor\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "vectorizers = {\n",
    "    \"Count Vectorizer\": CountVectorizer(),\n",
    "    \"TFIDF Vectorizer\": TfidfVectorizer(),\n",
    "    \"TFIDF Vectorizer w/ min_df=2\": TfidfVectorizer(min_df=2),\n",
    "    \"TFIDF Vectorizer w/ min_df=5\": TfidfVectorizer(min_df=5),\n",
    "    \"TFIDF Vectorizer w/ min_df=2, StopWords\": TfidfVectorizer(min_df=2, stop_words=\"english\"),\n",
    "    \"TFIDF Vectorizer w/ min_df=5, StopWords\": TfidfVectorizer(min_df=5, stop_words=\"english\"),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,2), min_df=2\": TfidfVectorizer(min_df=2, ngram_range=(1,2)),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,3), min_df=2\": TfidfVectorizer(min_df=2, ngram_range=(1,2)),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,2), min_df=5\": TfidfVectorizer(min_df=5, ngram_range=(1,2)),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,3), min_df=5\": TfidfVectorizer(min_df=5, ngram_range=(1,2)),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,2), min_df=2, StopWords\": TfidfVectorizer(min_df=2, ngram_range=(1,2), stop_words=\"english\"),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,3), min_df=2, StopWords\": TfidfVectorizer(min_df=2, ngram_range=(1,2), stop_words=\"english\"),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,2), min_df=5, StopWords\": TfidfVectorizer(min_df=5, ngram_range=(1,2), stop_words=\"english\"),\n",
    "    \"TFIDF Vectorizer w/ ngrams=(1,3), min_df=5, StopWords\": TfidfVectorizer(min_df=5, ngram_range=(1,2), stop_words=\"english\"),\n",
    "}\n",
    "all_targets = {\n",
    "    'Political Party':target_party, \n",
    "    'President':target_pres, \n",
    "    'Time Period':target_period\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Political Party models:\n",
      "\tUsing Count Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 0.9852744310575636\n",
      "\t\t\tTest  acc: 0.624\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.8808567603748326\n",
      "\t\t\tTest  acc: 0.68\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6305220883534136\n",
      "\t\t\tTest  acc: 0.472\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\losts\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9892904953145917\n",
      "\t\t\tTest  acc: 0.716\n",
      "\tUsing TFIDF Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.644\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.3453815261044177\n",
      "\t\t\tTest  acc: 0.32\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6546184738955824\n",
      "\t\t\tTest  acc: 0.584\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.46\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.6720214190093708\n",
      "\t\t\tTest  acc: 0.52\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.56\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.4685408299866131\n",
      "\t\t\tTest  acc: 0.352\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6666666666666666\n",
      "\t\t\tTest  acc: 0.532\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.484\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.678714859437751\n",
      "\t\t\tTest  acc: 0.54\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.524\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.4390896921017403\n",
      "\t\t\tTest  acc: 0.376\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6760374832663989\n",
      "\t\t\tTest  acc: 0.556\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.46\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7001338688085676\n",
      "\t\t\tTest  acc: 0.536\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.568\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.5983935742971888\n",
      "\t\t\tTest  acc: 0.516\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7911646586345381\n",
      "\t\t\tTest  acc: 0.676\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.48\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8781793842034806\n",
      "\t\t\tTest  acc: 0.692\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.576\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.678714859437751\n",
      "\t\t\tTest  acc: 0.46\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8152610441767069\n",
      "\t\t\tTest  acc: 0.688\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.452\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8714859437751004\n",
      "\t\t\tTest  acc: 0.716\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.62\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.4203480589022758\n",
      "\t\t\tTest  acc: 0.348\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5220883534136547\n",
      "\t\t\tTest  acc: 0.4\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.468\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7590361445783133\n",
      "\t\t\tTest  acc: 0.58\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.624\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.4564926372155288\n",
      "\t\t\tTest  acc: 0.38\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5113788487282463\n",
      "\t\t\tTest  acc: 0.42\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.48\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7951807228915663\n",
      "\t\t\tTest  acc: 0.58\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.608\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.41633199464524767\n",
      "\t\t\tTest  acc: 0.372\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5595716198125836\n",
      "\t\t\tTest  acc: 0.436\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.472\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7617135207496654\n",
      "\t\t\tTest  acc: 0.596\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.516\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.40160642570281124\n",
      "\t\t\tTest  acc: 0.336\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5756358768406962\n",
      "\t\t\tTest  acc: 0.5\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.364\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7469879518072289\n",
      "\t\t\tTest  acc: 0.556\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.68\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6171352074966533\n",
      "\t\t\tTest  acc: 0.38\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8032128514056225\n",
      "\t\t\tTest  acc: 0.644\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.488\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8862115127175368\n",
      "\t\t\tTest  acc: 0.66\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.64\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.5930388219544847\n",
      "\t\t\tTest  acc: 0.392\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7777777777777778\n",
      "\t\t\tTest  acc: 0.608\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.42\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8995983935742972\n",
      "\t\t\tTest  acc: 0.672\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.56\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6546184738955824\n",
      "\t\t\tTest  acc: 0.472\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7817938420348058\n",
      "\t\t\tTest  acc: 0.684\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.432\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8875502008032129\n",
      "\t\t\tTest  acc: 0.732\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.58\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6305220883534136\n",
      "\t\t\tTest  acc: 0.496\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7898259705488622\n",
      "\t\t\tTest  acc: 0.712\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.456\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8942436412315931\n",
      "\t\t\tTest  acc: 0.66\n",
      "President models:\n",
      "\tUsing Count Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.456\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.8888888888888888\n",
      "\t\t\tTest  acc: 0.532\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5287817938420348\n",
      "\t\t\tTest  acc: 0.264\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\losts\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9879518072289156\n",
      "\t\t\tTest  acc: 0.644\n",
      "\tUsing TFIDF Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.488\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.09504685408299866\n",
      "\t\t\tTest  acc: 0.072\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6224899598393574\n",
      "\t\t\tTest  acc: 0.38\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.348\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.5515394912985274\n",
      "\t\t\tTest  acc: 0.4\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.456\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.13119143239625167\n",
      "\t\t\tTest  acc: 0.088\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5876840696117804\n",
      "\t\t\tTest  acc: 0.376\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.312\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.5127175368139224\n",
      "\t\t\tTest  acc: 0.356\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.42\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.17670682730923695\n",
      "\t\t\tTest  acc: 0.14\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6251673360107095\n",
      "\t\t\tTest  acc: 0.472\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.356\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.5220883534136547\n",
      "\t\t\tTest  acc: 0.344\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.54\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.48728246318607765\n",
      "\t\t\tTest  acc: 0.22\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7376171352074966\n",
      "\t\t\tTest  acc: 0.584\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.34\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8005354752342704\n",
      "\t\t\tTest  acc: 0.492\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.376\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.5542168674698795\n",
      "\t\t\tTest  acc: 0.296\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7309236947791165\n",
      "\t\t\tTest  acc: 0.548\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.38\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8085676037483266\n",
      "\t\t\tTest  acc: 0.544\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.556\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.21552878179384202\n",
      "\t\t\tTest  acc: 0.152\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.3895582329317269\n",
      "\t\t\tTest  acc: 0.272\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.34\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.643908969210174\n",
      "\t\t\tTest  acc: 0.372\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.508\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.18206157965194109\n",
      "\t\t\tTest  acc: 0.088\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.3828647925033467\n",
      "\t\t\tTest  acc: 0.22\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.356\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.6305220883534136\n",
      "\t\t\tTest  acc: 0.32\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.396\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.16733601070950468\n",
      "\t\t\tTest  acc: 0.088\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.4685408299866131\n",
      "\t\t\tTest  acc: 0.316\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.324\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.607764390896921\n",
      "\t\t\tTest  acc: 0.312\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.436\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.23427041499330656\n",
      "\t\t\tTest  acc: 0.14\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.48460508701472554\n",
      "\t\t\tTest  acc: 0.304\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.292\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.5997322623828648\n",
      "\t\t\tTest  acc: 0.392\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.56\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.570281124497992\n",
      "\t\t\tTest  acc: 0.224\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7710843373493976\n",
      "\t\t\tTest  acc: 0.536\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.356\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8366800535475234\n",
      "\t\t\tTest  acc: 0.44\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.624\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6398929049531459\n",
      "\t\t\tTest  acc: 0.244\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7376171352074966\n",
      "\t\t\tTest  acc: 0.54\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.308\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8340026773761714\n",
      "\t\t\tTest  acc: 0.46\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.52\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6479250334672021\n",
      "\t\t\tTest  acc: 0.3\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7269076305220884\n",
      "\t\t\tTest  acc: 0.608\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.356\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8326639892904953\n",
      "\t\t\tTest  acc: 0.46\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.488\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6412315930388219\n",
      "\t\t\tTest  acc: 0.348\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.7429718875502008\n",
      "\t\t\tTest  acc: 0.576\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.328\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.821954484605087\n",
      "\t\t\tTest  acc: 0.48\n",
      "Time Period models:\n",
      "\tUsing Count Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.62\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.9464524765729585\n",
      "\t\t\tTest  acc: 0.74\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5943775100401606\n",
      "\t\t\tTest  acc: 0.408\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\losts\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9933065595716198\n",
      "\t\t\tTest  acc: 0.708\n",
      "\tUsing TFIDF Vectorizer as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.672\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.19812583668005354\n",
      "\t\t\tTest  acc: 0.168\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6452476572958501\n",
      "\t\t\tTest  acc: 0.552\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.48\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.6934404283801874\n",
      "\t\t\tTest  acc: 0.604\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.604\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.24230254350736277\n",
      "\t\t\tTest  acc: 0.196\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6760374832663989\n",
      "\t\t\tTest  acc: 0.54\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.468\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7215528781793842\n",
      "\t\t\tTest  acc: 0.532\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.576\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.2101740294511379\n",
      "\t\t\tTest  acc: 0.184\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.6706827309236948\n",
      "\t\t\tTest  acc: 0.624\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.404\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.714859437751004\n",
      "\t\t\tTest  acc: 0.628\n",
      "\tUsing TFIDF Vectorizer w/ min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.624\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6613119143239625\n",
      "\t\t\tTest  acc: 0.504\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8139223560910308\n",
      "\t\t\tTest  acc: 0.764\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.552\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9370816599732262\n",
      "\t\t\tTest  acc: 0.72\n",
      "\tUsing TFIDF Vectorizer w/ min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.596\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6599732262382865\n",
      "\t\t\tTest  acc: 0.436\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8487282463186078\n",
      "\t\t\tTest  acc: 0.704\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.452\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9156626506024096\n",
      "\t\t\tTest  acc: 0.676\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.716\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.31057563587684067\n",
      "\t\t\tTest  acc: 0.208\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.4926372155287818\n",
      "\t\t\tTest  acc: 0.34\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.504\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.8018741633199464\n",
      "\t\t\tTest  acc: 0.58\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.684\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.3507362784471218\n",
      "\t\t\tTest  acc: 0.22\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.4979919678714859\n",
      "\t\t\tTest  acc: 0.364\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.48\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7951807228915663\n",
      "\t\t\tTest  acc: 0.572\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.608\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.3293172690763052\n",
      "\t\t\tTest  acc: 0.224\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5502008032128514\n",
      "\t\t\tTest  acc: 0.412\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.492\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7898259705488622\n",
      "\t\t\tTest  acc: 0.58\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5 as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.62\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.3119143239625167\n",
      "\t\t\tTest  acc: 0.256\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.5448460508701473\n",
      "\t\t\tTest  acc: 0.436\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.468\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.7938420348058902\n",
      "\t\t\tTest  acc: 0.552\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.72\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6760374832663989\n",
      "\t\t\tTest  acc: 0.396\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8259705488621151\n",
      "\t\t\tTest  acc: 0.752\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.468\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9544846050870147\n",
      "\t\t\tTest  acc: 0.624\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=2, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.736\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6331994645247657\n",
      "\t\t\tTest  acc: 0.34\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8072289156626506\n",
      "\t\t\tTest  acc: 0.708\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.48\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9504685408299867\n",
      "\t\t\tTest  acc: 0.716\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,2), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.652\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.6921017402945113\n",
      "\t\t\tTest  acc: 0.5\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8393574297188755\n",
      "\t\t\tTest  acc: 0.696\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.444\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9424364123159303\n",
      "\t\t\tTest  acc: 0.688\n",
      "\tUsing TFIDF Vectorizer w/ ngrams=(1,3), min_df=5, StopWords as vect:\n",
      "\t\tGaussian Naive Bayes:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.648\n",
      "\t\tMultinomialNB:\n",
      "\t\t\tTrain acc: 0.7161981258366801\n",
      "\t\t\tTest  acc: 0.528\n",
      "\t\tk-Nearest Neighbor:\n",
      "\t\t\tTrain acc: 0.8299866131191432\n",
      "\t\t\tTest  acc: 0.76\n",
      "\t\tDecision Tree:\n",
      "\t\t\tTrain acc: 1.0\n",
      "\t\t\tTest  acc: 0.512\n",
      "\t\tLogistic Regression:\n",
      "\t\t\tTrain acc: 0.9598393574297188\n",
      "\t\t\tTest  acc: 0.764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for target_name, target in all_targets.items():\n",
    "    print(f\"{target_name} models:\")\n",
    "    \n",
    "    for vect_name, vectorizer in vectorizers.items():\n",
    "        print(f\"\\tUsing {vect_name} as vect:\")\n",
    "        \n",
    "        for estimator_name, estimator in estimators.items():\n",
    "            X_train, X_test, y_train, y_test = train_test_split(text, target)\n",
    "            \n",
    "            vect = vectorizer.fit(X_train)\n",
    "            \n",
    "            X_train_vect = vect.transform(X_train).toarray()\n",
    "            X_test_vect = vect.transform(X_test).toarray()\n",
    "            \n",
    "            estimator.fit(X=X_train_vect, y=y_train)\n",
    "            \n",
    "            print(f\"\\t\\t{estimator_name}:\")\n",
    "            print(f\"\\t\\t\\tTrain acc: {estimator.score(X_train_vect, y_train)}\")\n",
    "            print(f\"\\t\\t\\tTest  acc: {estimator.score(X_test_vect, y_test)}\")\n",
    "            \n",
    "# X_train, X_test, y_train, y_test = train_test_split(text, target_party)\n",
    "\n",
    "# vect = CountVectorizer().fit(X_train)\n",
    "# #vect = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "# X_train_vectorized = vect.transform(X_train)\n",
    "# X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "# model = MultinomialNB(alpha = 0.5).fit(X=X_train_vectorized, y=y_train)\n",
    "# print(model.score(X_train_vectorized, y_train))\n",
    "# print(model.score(X_test_vectorized, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Political Party\n",
      "df=2, stops=None, ngram_range=(1, 1)\n",
      "train=0.6398929049531459\n",
      "testt=0.532\n",
      "df=2, stops=None, ngram_range=(1, 2)\n",
      "train=0.4886211512717537\n",
      "testt=0.404\n",
      "df=2, stops=None, ngram_range=(2, 2)\n",
      "train=0.6211512717536813\n",
      "testt=0.488\n",
      "df=2, stops=None, ngram_range=(1, 3)\n",
      "train=0.4149933065595716\n",
      "testt=0.348\n",
      "df=2, stops=None, ngram_range=(2, 3)\n",
      "train=0.6506024096385542\n",
      "testt=0.504\n",
      "df=2, stops=None, ngram_range=(3, 3)\n",
      "train=0.8340026773761714\n",
      "testt=0.748\n",
      "df=2, stops=english, ngram_range=(1, 1)\n",
      "train=0.7657295850066934\n",
      "testt=0.692\n",
      "df=2, stops=english, ngram_range=(1, 2)\n",
      "train=0.7617135207496654\n",
      "testt=0.716\n",
      "df=2, stops=english, ngram_range=(2, 2)\n",
      "train=0.8393574297188755\n",
      "testt=0.764\n",
      "df=2, stops=english, ngram_range=(1, 3)\n",
      "train=0.7643908969210174\n",
      "testt=0.72\n",
      "df=2, stops=english, ngram_range=(2, 3)\n",
      "train=0.8487282463186078\n",
      "testt=0.72\n",
      "df=2, stops=english, ngram_range=(3, 3)\n",
      "train=0.821954484605087\n",
      "testt=0.648\n",
      "df=3, stops=None, ngram_range=(1, 1)\n",
      "train=0.6492637215528781\n",
      "testt=0.54\n",
      "df=3, stops=None, ngram_range=(1, 2)\n",
      "train=0.5180722891566265\n",
      "testt=0.436\n",
      "df=3, stops=None, ngram_range=(2, 2)\n",
      "train=0.6358768406961178\n",
      "testt=0.504\n",
      "df=3, stops=None, ngram_range=(1, 3)\n",
      "train=0.4578313253012048\n",
      "testt=0.4\n",
      "df=3, stops=None, ngram_range=(2, 3)\n",
      "train=0.6546184738955824\n",
      "testt=0.544\n",
      "df=3, stops=None, ngram_range=(3, 3)\n",
      "train=0.8179384203480589\n",
      "testt=0.756\n",
      "df=3, stops=english, ngram_range=(1, 1)\n",
      "train=0.7643908969210174\n",
      "testt=0.7\n",
      "df=3, stops=english, ngram_range=(1, 2)\n",
      "train=0.7684069611780455\n",
      "testt=0.708\n",
      "df=3, stops=english, ngram_range=(2, 2)\n",
      "train=0.8232931726907631\n",
      "testt=0.716\n",
      "df=3, stops=english, ngram_range=(1, 3)\n",
      "train=0.7710843373493976\n",
      "testt=0.712\n",
      "df=3, stops=english, ngram_range=(2, 3)\n",
      "train=0.8340026773761714\n",
      "testt=0.72\n",
      "df=3, stops=english, ngram_range=(3, 3)\n",
      "train=0.2891566265060241\n",
      "testt=0.176\n",
      "df=4, stops=None, ngram_range=(1, 1)\n",
      "train=0.6586345381526104\n",
      "testt=0.54\n",
      "df=4, stops=None, ngram_range=(1, 2)\n",
      "train=0.535475234270415\n",
      "testt=0.464\n",
      "df=4, stops=None, ngram_range=(2, 2)\n",
      "train=0.643908969210174\n",
      "testt=0.504\n",
      "df=4, stops=None, ngram_range=(1, 3)\n",
      "train=0.4966532797858099\n",
      "testt=0.428\n",
      "df=4, stops=None, ngram_range=(2, 3)\n",
      "train=0.6666666666666666\n",
      "testt=0.548\n",
      "df=4, stops=None, ngram_range=(3, 3)\n",
      "train=0.8058902275769746\n",
      "testt=0.752\n",
      "df=4, stops=english, ngram_range=(1, 1)\n",
      "train=0.7670682730923695\n",
      "testt=0.696\n",
      "df=4, stops=english, ngram_range=(1, 2)\n",
      "train=0.7764390896921017\n",
      "testt=0.708\n",
      "df=4, stops=english, ngram_range=(2, 2)\n",
      "train=0.8232931726907631\n",
      "testt=0.724\n",
      "df=4, stops=english, ngram_range=(1, 3)\n",
      "train=0.785809906291834\n",
      "testt=0.708\n",
      "df=4, stops=english, ngram_range=(2, 3)\n",
      "train=0.8232931726907631\n",
      "testt=0.704\n",
      "df=4, stops=english, ngram_range=(3, 3)\n",
      "train=0.3172690763052209\n",
      "testt=0.2\n",
      "df=5, stops=None, ngram_range=(1, 1)\n",
      "train=0.6653279785809906\n",
      "testt=0.54\n",
      "df=5, stops=None, ngram_range=(1, 2)\n",
      "train=0.5515394912985274\n",
      "testt=0.476\n",
      "df=5, stops=None, ngram_range=(2, 2)\n",
      "train=0.643908969210174\n",
      "testt=0.524\n",
      "df=5, stops=None, ngram_range=(1, 3)\n",
      "train=0.5153949129852744\n",
      "testt=0.44\n",
      "df=5, stops=None, ngram_range=(2, 3)\n",
      "train=0.6666666666666666\n",
      "testt=0.548\n",
      "df=5, stops=None, ngram_range=(3, 3)\n",
      "train=0.8085676037483266\n",
      "testt=0.732\n",
      "df=5, stops=english, ngram_range=(1, 1)\n",
      "train=0.7670682730923695\n",
      "testt=0.704\n",
      "df=5, stops=english, ngram_range=(1, 2)\n",
      "train=0.7724230254350736\n",
      "testt=0.708\n",
      "df=5, stops=english, ngram_range=(2, 2)\n",
      "train=0.821954484605087\n",
      "testt=0.708\n",
      "df=5, stops=english, ngram_range=(1, 3)\n",
      "train=0.784471218206158\n",
      "testt=0.724\n",
      "df=5, stops=english, ngram_range=(2, 3)\n",
      "train=0.8179384203480589\n",
      "testt=0.688\n",
      "df=5, stops=english, ngram_range=(3, 3)\n",
      "train=0.27710843373493976\n",
      "testt=0.192\n",
      "\n",
      "President\n",
      "df=2, stops=None, ngram_range=(1, 1)\n",
      "train=0.6131191432396251\n",
      "testt=0.424\n",
      "df=2, stops=None, ngram_range=(1, 2)\n",
      "train=0.4390896921017403\n",
      "testt=0.28\n",
      "df=2, stops=None, ngram_range=(2, 2)\n",
      "train=0.5756358768406962\n",
      "testt=0.356\n",
      "df=2, stops=None, ngram_range=(1, 3)\n",
      "train=0.35207496653279785\n",
      "testt=0.228\n",
      "df=2, stops=None, ngram_range=(2, 3)\n",
      "train=0.6024096385542169\n",
      "testt=0.36\n",
      "df=2, stops=None, ngram_range=(3, 3)\n",
      "train=0.8072289156626506\n",
      "testt=0.64\n",
      "df=2, stops=english, ngram_range=(1, 1)\n",
      "train=0.7536813922356091\n",
      "testt=0.528\n",
      "df=2, stops=english, ngram_range=(1, 2)\n",
      "train=0.7536813922356091\n",
      "testt=0.544\n",
      "df=2, stops=english, ngram_range=(2, 2)\n",
      "train=0.8232931726907631\n",
      "testt=0.624\n",
      "df=2, stops=english, ngram_range=(1, 3)\n",
      "train=0.7536813922356091\n",
      "testt=0.552\n",
      "df=2, stops=english, ngram_range=(2, 3)\n",
      "train=0.820615796519411\n",
      "testt=0.604\n",
      "df=2, stops=english, ngram_range=(3, 3)\n",
      "train=0.7978580990629184\n",
      "testt=0.48\n",
      "df=3, stops=None, ngram_range=(1, 1)\n",
      "train=0.6184738955823293\n",
      "testt=0.428\n",
      "df=3, stops=None, ngram_range=(1, 2)\n",
      "train=0.46987951807228917\n",
      "testt=0.292\n",
      "df=3, stops=None, ngram_range=(2, 2)\n",
      "train=0.5783132530120482\n",
      "testt=0.348\n",
      "df=3, stops=None, ngram_range=(1, 3)\n",
      "train=0.40829986613119146\n",
      "testt=0.244\n",
      "df=3, stops=None, ngram_range=(2, 3)\n",
      "train=0.607764390896921\n",
      "testt=0.372\n",
      "df=3, stops=None, ngram_range=(3, 3)\n",
      "train=0.7898259705488622\n",
      "testt=0.572\n",
      "df=3, stops=english, ngram_range=(1, 1)\n",
      "train=0.7483266398929049\n",
      "testt=0.524\n",
      "df=3, stops=english, ngram_range=(1, 2)\n",
      "train=0.751004016064257\n",
      "testt=0.556\n",
      "df=3, stops=english, ngram_range=(2, 2)\n",
      "train=0.8018741633199464\n",
      "testt=0.604\n",
      "df=3, stops=english, ngram_range=(1, 3)\n",
      "train=0.751004016064257\n",
      "testt=0.54\n",
      "df=3, stops=english, ngram_range=(2, 3)\n",
      "train=0.8125836680053548\n",
      "testt=0.608\n",
      "df=3, stops=english, ngram_range=(3, 3)\n",
      "train=0.13386880856760375\n",
      "testt=0.048\n",
      "df=4, stops=None, ngram_range=(1, 1)\n",
      "train=0.6184738955823293\n",
      "testt=0.44\n",
      "df=4, stops=None, ngram_range=(1, 2)\n",
      "train=0.4819277108433735\n",
      "testt=0.312\n",
      "df=4, stops=None, ngram_range=(2, 2)\n",
      "train=0.5903614457831325\n",
      "testt=0.36\n",
      "df=4, stops=None, ngram_range=(1, 3)\n",
      "train=0.43775100401606426\n",
      "testt=0.26\n",
      "df=4, stops=None, ngram_range=(2, 3)\n",
      "train=0.606425702811245\n",
      "testt=0.396\n",
      "df=4, stops=None, ngram_range=(3, 3)\n",
      "train=0.7804551539491299\n",
      "testt=0.56\n",
      "df=4, stops=english, ngram_range=(1, 1)\n",
      "train=0.7523427041499331\n",
      "testt=0.54\n",
      "df=4, stops=english, ngram_range=(1, 2)\n",
      "train=0.7523427041499331\n",
      "testt=0.552\n",
      "df=4, stops=english, ngram_range=(2, 2)\n",
      "train=0.8045515394912985\n",
      "testt=0.572\n",
      "df=4, stops=english, ngram_range=(1, 3)\n",
      "train=0.7576974564926372\n",
      "testt=0.536\n",
      "df=4, stops=english, ngram_range=(2, 3)\n",
      "train=0.8045515394912985\n",
      "testt=0.568\n",
      "df=4, stops=english, ngram_range=(3, 3)\n",
      "train=0.3119143239625167\n",
      "testt=0.072\n",
      "df=5, stops=None, ngram_range=(1, 1)\n",
      "train=0.6198125836680054\n",
      "testt=0.44\n",
      "df=5, stops=None, ngram_range=(1, 2)\n",
      "train=0.5060240963855421\n",
      "testt=0.324\n",
      "df=5, stops=None, ngram_range=(2, 2)\n",
      "train=0.5890227576974565\n",
      "testt=0.376\n",
      "df=5, stops=None, ngram_range=(1, 3)\n",
      "train=0.45113788487282463\n",
      "testt=0.28\n",
      "df=5, stops=None, ngram_range=(2, 3)\n",
      "train=0.6117804551539491\n",
      "testt=0.408\n",
      "df=5, stops=None, ngram_range=(3, 3)\n",
      "train=0.7724230254350736\n",
      "testt=0.56\n",
      "df=5, stops=english, ngram_range=(1, 1)\n",
      "train=0.7469879518072289\n",
      "testt=0.544\n",
      "df=5, stops=english, ngram_range=(1, 2)\n",
      "train=0.7550200803212851\n",
      "testt=0.548\n",
      "df=5, stops=english, ngram_range=(2, 2)\n",
      "train=0.785809906291834\n",
      "testt=0.548\n",
      "df=5, stops=english, ngram_range=(1, 3)\n",
      "train=0.7536813922356091\n",
      "testt=0.548\n",
      "df=5, stops=english, ngram_range=(2, 3)\n",
      "train=0.7751004016064257\n",
      "testt=0.556\n",
      "df=5, stops=english, ngram_range=(3, 3)\n",
      "train=0.250334672021419\n",
      "testt=0.068\n"
     ]
    }
   ],
   "source": [
    "# Doing TfidfVectorizer things:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "min_df_ops = [2,3,4,5]\n",
    "stop_words_ops = [None, \"english\"]\n",
    "ngram_range_ops = [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]\n",
    "#params = {\"min_df\":[2,3,4,5], \"stop_words\":[None, \"enlgish\"], \"ngram_range\":[(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]}\n",
    "\n",
    "\n",
    "for target_name, target in all_targets.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(text, target)\n",
    "    if target_name == \"Time Period\":\n",
    "        continue\n",
    "    print(f\"\\n{target_name}\")\n",
    "    for m_df in min_df_ops:\n",
    "        for stops in stop_words_ops:\n",
    "            for ngrams in ngram_range_ops:\n",
    "                vect = TfidfVectorizer(min_df=m_df, ngram_range=ngrams, stop_words=stops)\n",
    "                vect = vect.fit(X_train)\n",
    "\n",
    "                estimator = KNeighborsClassifier()\n",
    "\n",
    "                X_train_vect = vect.transform(X_train).toarray()\n",
    "                X_test_vect = vect.transform(X_test).toarray()\n",
    "\n",
    "                estimator.fit(X=X_train_vect, y=y_train)\n",
    "                print(f\"df={df}, stops={stops}, ngram_range={ngrams}\")\n",
    "                print(f\"train={estimator.score(X_train_vect, y_train)}\")\n",
    "                print(f\"testt={estimator.score(X_test_vect, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing TfidfVectorizer things:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "min_df_ops = [2,3,4,5]\n",
    "stop_words_ops = [None, \"english\"]\n",
    "ngram_range_ops = [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]\n",
    "#params = {\"min_df\":[2,3,4,5], \"stop_words\":[None, \"enlgish\"], \"ngram_range\":[(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)]}\n",
    "\n",
    "estimator = MLPClassifier(solver=\"lbfgs\", hidden_layer_sizes=(100, 50))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target_period)\n",
    "    \n",
    "vect = TfidfVectorizer(min_df=2, ngram_range=(1,2), stop_words=\"english\").fit(X_train)\n",
    "\n",
    "X_train_vect = vect.transform(X_train).toarray()\n",
    "X_test_vect = vect.transform(X_test).toarray()\n",
    "\n",
    "\n",
    "# estimator.fit(X=X_train_vect, y=y_train)\n",
    "\n",
    "# print(f\"\\t\\t{estimator_name}:\")\n",
    "# print(f\"\\t\\t\\tTrain acc: {estimator.score(X_train_vect, y_train)}\")\n",
    "# print(f\"\\t\\t\\tTest  acc: {estimator.score(X_test_vect, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
